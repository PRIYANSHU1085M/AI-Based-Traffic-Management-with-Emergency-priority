{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36df7e09-aca2-4024-9d08-f018caa4dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms \n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54718596-b186-4319-9119-8eea6c2cf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness_contrast(image):\n",
    "    transform = transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "    return transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a61307e9-91a5-4fcc-8e38-9ee72e494e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_scaling(image):\n",
    "    transform = transforms.RandomAffine(degrees=0, translate=(0.1,0.1), scale=(0.8,12))\n",
    "    return transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08d4dc30-ff08-4d79-b3b6-77f6f7cc82d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(image):\n",
    "    transform = transforms.ToTensor()\n",
    "    image_tensor = transform(image)\n",
    "    noise_image_tensor = image_tensor + 0.05 * torch.randn_like(image_tensor)\n",
    "    return transforms.ToPILImage()(noise_image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c2c9412-fc6d-4bac-b7cd-8457661a119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_jitter(image):\n",
    "    transform = transforms.ColorJitter(hue=0.1, saturation=0.1)\n",
    "    return transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c7641c9-c0a9-44e7-a94c-0ae1432ca7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"D:\\\\ML\\\\d\\\\vehivle detection 2.v4i.yolov5pytorch\\\\train\\\\images\"\n",
    "label_dir = \"D:\\\\ML\\\\d\\\\vehivle detection 2.v4i.yolov5pytorch\\\\train\\\\labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9954bc64-6103-48a8-8c3e-0613d4836fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image_path,label_path):\n",
    "    image = Image.open(image_path)\n",
    "    filename = os.path.basename(image_path).split('.')[0]\n",
    "    dir = os.path.dirname(image_path)\n",
    "    label_dir = os.path.dirname(label_path)\n",
    "\n",
    "    augmentation=[\n",
    "        (brightness_contrast, 'bright'),\n",
    "        (gaussian_noise, 'noise'),\n",
    "        (color_jitter, 'color')\n",
    "    ]\n",
    "\n",
    "    for transform,suffix in augmentation:\n",
    "        augmented_image = transform(image)\n",
    "        augmented_image_path = os.path.join(dir,f\"{filename}_{suffix}.jpg\")\n",
    "        augmented_image.save(augmented_image_path)\n",
    "\n",
    "        label_name = f\"{filename}.txt\"\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                labels = f.readlines()\n",
    "\n",
    "            augmented_label_path = os.path.join(label_dir,f\"{filename}_{suffix}.txt\")\n",
    "            with open(augmented_label_path, 'w') as f:\n",
    "                f.writelines(labels)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48a4be6c-1ccf-4c43-bf80-b7fdd182891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_dir,filename)\n",
    "        label_path = os.path.join(label_dir,f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        augment(image_path,label_path)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "440970df-9dc7-4963-9263-2699d2396306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define paths\n",
    "dataset_dir = 'D:\\\\ML\\\\d\\\\vehivle detection 2.v4i.yolov5pytorch\\\\train'\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'valid')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for d in [train_dir, val_dir, test_dir]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(os.path.join(d, 'images'))\n",
    "        os.makedirs(os.path.join(d, 'labels'))\n",
    "\n",
    "# List all images and labels\n",
    "images = [f for f in os.listdir(os.path.join(dataset_dir, 'images')) if f.endswith('.jpg')]\n",
    "labels = [f for f in os.listdir(os.path.join(dataset_dir, 'labels')) if f.endswith('.txt')]\n",
    "\n",
    "# Ensure every image has a corresponding label\n",
    "assert len(images) == len(labels), \"Number of images and labels must match\"\n",
    "\n",
    "# Shuffle images\n",
    "random.shuffle(images)\n",
    "\n",
    "# Split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Calculate split sizes\n",
    "total = len(images)\n",
    "train_size = int(total * train_ratio)\n",
    "val_size = int(total * val_ratio)\n",
    "\n",
    "# Split data\n",
    "train_images = images[:train_size]\n",
    "val_images = images[train_size:train_size+val_size]\n",
    "test_images = images[train_size+val_size:]\n",
    "\n",
    "# Copy files to respective directories\n",
    "def copy_files(file_list, src_dir, dest_dir):\n",
    "    for file_name in file_list:\n",
    "        # Copy image\n",
    "        shutil.copy(os.path.join(src_dir, 'images', file_name), os.path.join(dest_dir, 'images', file_name))\n",
    "        # Copy label\n",
    "        label_file = file_name.rsplit('.', 1)[0] + '.txt'\n",
    "        if os.path.exists(os.path.join(src_dir, 'labels', label_file)):\n",
    "            shutil.copy(os.path.join(src_dir, 'labels', label_file), os.path.join(dest_dir, 'labels', label_file))\n",
    "\n",
    "copy_files(train_images, dataset_dir, train_dir)\n",
    "copy_files(val_images, dataset_dir, val_dir)\n",
    "copy_files(test_images, dataset_dir, test_dir)\n",
    "\n",
    "print(\"Dataset split completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b9dee-83c0-4888-9bc0-2fde0d888a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5\\train.py --img 320 --batch 32 --epochs 5 --data yolov5\\data.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c21106-cabe-403e-8528-f5adf7b4c6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
